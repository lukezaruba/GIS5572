{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Automated Data Quality Assurance Pipeline\n",
    "### Luke Zaruba\n",
    "### GIS 5572: ArcGIS II\n",
    "### 2023-03-09\n",
    "\n",
    "\n",
    "In this lab, the goal is to build a pipeline that will extract data, perform QAQC operations on the data, and the save the data locally in a File Geodatabase, before saving it to a PostgreSQL database hosted on Google Cloud.\n",
    "\n",
    "The way in which I do this is as follows:\n",
    "1. Use OOP to abstract different parts of the pipeline such as:\n",
    "    - Loading Data (RasterLoader, VectorLoader, DataLoader)\n",
    "    - Processing Data (RasterProcessor, VectorProcessor)\n",
    "    - Exporting Data (DataExporter)\n",
    "2. Take any given input dataset and put it into the DataLoader, which standardizes the format (to NumPy Arrays, which can represent both raster and vector data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arcpy\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, filepath, data_type):\n",
    "        self.filepath = filepath\n",
    "        self.data_type = data_type\n",
    "        self.data = None\n",
    "    \n",
    "    def load_data(self):\n",
    "        if self.data_type == \"raster\":\n",
    "            self.data = arcpy.RasterToNumPyArray(self.filepath)\n",
    "        elif self.data_type == \"vector\":\n",
    "            self.data = arcpy.FeatureClassToNumPyArray(self.filepath)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ">>> landcover_loader = DataLoader(r\"file/path/lc.tif\", \"raster\")\n",
    ">>> landcover_loader.load_data()\n",
    ">>> type(landcover_loader.data)\n",
    "... numpy.ndarray\n",
    "\n",
    ">>> landcover_processor = RasterDataProcessor(landcover_loader.data)\n",
    ">>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RasterDataProcessor:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.stats = None\n",
    "        self.spatial_resolution = None\n",
    "        self.crs = None\n",
    "        self.bbox = None\n",
    "    \n",
    "    def calculate_stats(self):\n",
    "        # Load to DF\n",
    "        df = pd.DataFrame(self.data)\n",
    "        # Calculate Stats\n",
    "        self.stats = df.describe()\n",
    "    \n",
    "    def check_quality(self):\n",
    "        # Check for missing or null values\n",
    "        nodata_val = self.data.noDataValue\n",
    "        if nodata_val is not None:\n",
    "            null_count = np.count_nonzero(self.data == nodata_val)\n",
    "            if null_count > 0:\n",
    "                print(f\"Warning: {null_count} null or missing values detected\")\n",
    "        \n",
    "        # Validate spatial resolution\n",
    "        cell_size_x = self.data.meanCellWidth\n",
    "        cell_size_y = self.data.meanCellHeight\n",
    "        self.spatial_resolution = (cell_size_x, cell_size_y)\n",
    "        if cell_size_x != cell_size_y:\n",
    "            print(\"Warning: non-square pixels detected\")\n",
    "        \n",
    "        # Validate coordinate system\n",
    "        self.crs = self.data.spatialReference\n",
    "        if not self.crs.name:\n",
    "            print(\"Warning: unknown coordinate system\")\n",
    "        else:\n",
    "            print(f\"Coordinate system: {self.crs.name}\")\n",
    "        \n",
    "        # Check if dataset is within a bounding box\n",
    "        extent = self.data.extent\n",
    "        self.bbox = (extent.XMin, extent.YMin, extent.XMax, extent.YMax)\n",
    "    \n",
    "        if self.bbox[0] < -180 or self.bbox[1] < -90 or self.bbox[2] > 180 or self.bbox[3] > 90:\n",
    "            print(\"Warning: data extends beyond the valid geographic extent (-180,-90,180,90)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDataProcessor:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.stats = None\n",
    "        self.crs = None\n",
    "        self.bbox = None\n",
    "        self.topology_errors = None\n",
    "    \n",
    "    def calculate_stats(self):\n",
    "        if isinstance(self.data, arcpy._mp.Layer):\n",
    "            df = pd.DataFrame.from_records(data=self.data)\n",
    "        else:\n",
    "            df = pd.DataFrame(self.data)\n",
    "        self.stats = df.describe()\n",
    "    \n",
    "    def check_quality(self):\n",
    "        # Check for missing or null values\n",
    "        fields = arcpy.ListFields(self.data)\n",
    "        for field in fields:\n",
    "            if field.name not in [\"OID\", \"Shape\", \"Shape_Length\", \"Shape_Area\"] and field.type in [\"Integer\", \"SmallInteger\", \"Single\", \"Double\"]:\n",
    "                null_count = arcpy.GetCount_management(self.data, f\"{field.name}\")\n",
    "                if null_count > 0:\n",
    "                    print(f\"Warning: {null_count} null or missing values detected in field {field.name}\")\n",
    "        \n",
    "        # Validate topology\n",
    "        arcpy.CheckGeometry_management(self.data)\n",
    "        if int(arcpy.GetMessageCount()) > 0:\n",
    "            self.topology_errors = arcpy.GetMessages()\n",
    "            print(\"Warning: topology errors detected\")\n",
    "        \n",
    "        # Validate coordinate system\n",
    "        self.crs = arcpy.Describe(self.data).spatialReference\n",
    "        if not self.crs.name:\n",
    "            print(\"Warning: unknown coordinate system\")\n",
    "        else:\n",
    "            print(f\"Coordinate system: {self.crs.name}\")\n",
    "        \n",
    "        # Check if dataset is within a bounding box\n",
    "        extent = arcpy.Describe(self.data).extent\n",
    "        self.bbox = (extent.XMin, extent.YMin, extent.XMax, extent.YMax)\n",
    "    \n",
    "        if self.bbox[0] < -180 or self.bbox[1] < -90 or self.bbox[2] > 180 or self.bbox[3] > 90:\n",
    "            print(\"Warning: data extends beyond the valid geographic extent (-180,-90,180,90)\")\n",
    "        \n",
    "        # Remove outliers within a given field\n",
    "        # To be implemented\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExporter:\n",
    "    def __init__(self, data, filepath):\n",
    "        self.data = data\n",
    "        self.filepath = filepath\n",
    "    \n",
    "    def export_data(self):\n",
    "        if isinstance(self.data, pd.DataFrame):\n",
    "            arcpy.da.NumPyArrayToFeatureClass(self.data.to_records(), self.filepath)\n",
    "        else:\n",
    "            self.data.save(self.filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAQC:\n",
    "    def __init__(self, filepath, data_type):\n",
    "        self.filepath = filepath\n",
    "        self.data_type = data_type\n",
    "        self.dataloader = DataLoader(filepath, data_type)\n",
    "        self.dataprocessor = DataProcessor(self.dataloader.data)\n",
    "        self.dataexporter = DataExporter(self.dataprocessor.stats, f\"{filepath}_stats\")\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        self.dataloader.load_data()\n",
    "        self.dataprocessor.calculate_stats()\n",
    "        self.dataprocessor.check_quality()\n",
    "        self.dataexporter.export_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "def8e632b3bf617b9a70480f352dd1a48ccae5bc3982940c0141c66988093451"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
